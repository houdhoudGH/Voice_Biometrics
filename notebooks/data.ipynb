{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import joblib\n",
    "import librosa\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/data_test_train'  \n",
    "NUM_COMPONENTS = 128  \n",
    "NUM_IVECTORS = 13     \n",
    "COVARIANCE_TYPE = 'diag' \n",
    "EPS = 1e-6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubm = joblib.load('ubm_model.pkl') \n",
    "t_matrix = joblib.load('t_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(y):\n",
    "    return librosa.util.normalize(y)\n",
    "\n",
    "def extract_mfcc(audio_file):\n",
    "    y, sr = librosa.load(audio_file, sr=16000)\n",
    "    y = normalize_audio(y)  \n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    delta_mfcc = librosa.feature.delta(mfcc)\n",
    "    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "    mfcc_features = np.concatenate((mfcc, delta_mfcc, delta2_mfcc), axis=0)  \n",
    "    return mfcc_features.T  \n",
    "\n",
    "def compute_baum_welch_statistics(mfccs, ubm):\n",
    "    responsibilities = ubm.predict_proba(mfccs)\n",
    "    N = np.sum(responsibilities, axis=0)\n",
    "    F = np.dot(responsibilities.T, mfccs)\n",
    "    return N, F\n",
    "\n",
    "def extract_ivector(F, N, t_matrix):\n",
    "    N = N + EPS\n",
    "    ivector = t_matrix.transform(F / N[:, np.newaxis])\n",
    "    return ivector.flatten() \n",
    "\n",
    "def length_normalize(ivector):\n",
    "    return ivector / np.linalg.norm(ivector)\n",
    "\n",
    "def train_plda(ivectors, labels):\n",
    "    plda = LinearDiscriminantAnalysis()\n",
    "    plda.fit(ivectors, labels)\n",
    "    return plda\n",
    "\n",
    "def verify_speaker_plda(test_ivector, reference_ivector, plda):\n",
    "    test_ivector = test_ivector.reshape(1, -1)\n",
    "    reference_ivector = reference_ivector.reshape(1, -1)\n",
    "    score = plda.predict_proba(np.vstack((test_ivector, reference_ivector)))[0, 1]\n",
    "    return score\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    audio_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith((\".mp3\",\".mp4\",\".wav\",\".flac\"))]\n",
    "\n",
    "    ivectors = []\n",
    "    for audio_file in audio_files:\n",
    "        mfcc_features = extract_mfcc(audio_file)\n",
    "        scaler = StandardScaler()\n",
    "        mfcc_features = scaler.fit_transform(mfcc_features)\n",
    "        N, F = compute_baum_welch_statistics(mfcc_features, ubm)\n",
    "        ivector = extract_ivector(F, N, t_matrix)\n",
    "        ivector = length_normalize(ivector)\n",
    "        ivectors.append(ivector)\n",
    "\n",
    "    return ivectors\n",
    "\n",
    "def create_dataset(data_folder):\n",
    "    dataset = []\n",
    "\n",
    "    for folder_name in os.listdir(data_folder):\n",
    "        folder_path = os.path.join(data_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "                ivector1, ivector2 = process_folder(folder_path)\n",
    "                dataset.append({\n",
    "                    'label': 1,\n",
    "                    'ivector1': ivector1,\n",
    "                    'ivector2': ivector2\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = create_dataset(DATA_FOLDER)\n",
    "dataset_df.to_csv('speaker_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
