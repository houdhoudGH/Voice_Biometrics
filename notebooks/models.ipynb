{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries \n",
    "These libraries are used for data manipulation (pandas, numpy), audio processing (librosa), machine learning (sklearn), and saving/loading models (joblib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Constants\n",
    "NUM_COMPONENTS: The number of Gaussian components in the UBM. A higher number allows the model to capture more complex distributions but increases computational cost.\n",
    "  - NUM_IVECTORS: The dimensionality of the i-vectors. This is the reduced dimension after applying PCA to the Baum-Welch statistics.\n",
    "  - COVARIANCE_TYPE: The type of covariance matrix used in the GMM. 'diag' assumes diagonal covariance matrices, which simplifies computation.\n",
    "  - EPS: A small constant to avoid division by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = '../data/clips'\n",
    "NUM_COMPONENTS = 128  \n",
    "NUM_IVECTORS = 13     \n",
    "COVARIANCE_TYPE = 'diag'\n",
    "EPS = 1e-6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Preprocessing and Feature Extraction\n",
    "Normalization*: Normalizes the audio signal to have zero mean and unit variance, which helps in stabilizing the feature extraction process.\n",
    "  - *MFCCs*: Mel-Frequency Cepstral Coefficients are a representation of the short-term power spectrum of a sound. They are widely used in speech processing because they capture the characteristics of the human voice.\n",
    "  - *Delta and Delta-Delta*: These are the first and second derivatives of the MFCCs, capturing dynamic information about how the MFCCs change over time.\n",
    "  - *Concatenation*: Combines the MFCCs, delta, and delta-delta features into a single feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(y):\n",
    "    return librosa.util.normalize(y)\n",
    "\n",
    "def extract_mfcc(audio_file):\n",
    "    y, sr = librosa.load(audio_file, sr=16000)\n",
    "    y = normalize_audio(y)  \n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    delta_mfcc = librosa.feature.delta(mfcc)\n",
    "    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "    mfcc_features = np.concatenate((mfcc, delta_mfcc, delta2_mfcc), axis=0)  \n",
    "    return mfcc_features.T  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baum-Welch Statistics\n",
    "The posterior probabilities that a feature vector belongs to each Gaussian component in the UBM.\n",
    "  - *N*: The zero-order Baum-Welch statistic, representing the total responsibility of each Gaussian component.\n",
    "  - *F*: The first-order Baum-Welch statistic, representing the weighted sum of the feature vectors for each Gaussian component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_baum_welch_statistics(mfccs, ubm):\n",
    "    responsibilities = ubm.predict_proba(mfccs)\n",
    "    N = np.sum(responsibilities, axis=0)\n",
    "    F = np.dot(responsibilities.T, mfccs)\n",
    "    return N, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i-Vector Extraction\n",
    "- *i-Vector*: A low-dimensional representation of the speaker characteristics. It is obtained by projecting the Baum-Welch statistics onto a low-dimensional subspace (defined by the T-matrix).\n",
    "- *T-Matrix*: A matrix that maps the high-dimensional Baum-Welch statistics to the low-dimensional i-vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ivector(F, N, t_matrix):\n",
    "    N = N + EPS\n",
    "    ivector = t_matrix.transform(F / N[:, np.newaxis])\n",
    "    return ivector.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length Normalization\n",
    "- *Length Normalization*: Ensures that the i-vectors lie on a hypersphere, which improves the performance of the speaker verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_normalize(ivector):\n",
    "    return ivector / np.linalg.norm(ivector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLDA Training\n",
    "- *PLDA*: A generative model that captures the variability between speakers and within-speaker variability. It is used to compute the likelihood ratio for speaker verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_plda(ivectors, labels):\n",
    "    plda = LinearDiscriminantAnalysis()\n",
    "    plda.fit(ivectors, labels)\n",
    "    return plda\n",
    "\n",
    "def verify_speaker_plda(test_ivector, reference_ivector, plda):\n",
    "    test_ivector = test_ivector.reshape(1, -1)\n",
    "    reference_ivector = reference_ivector.reshape(1, -1)\n",
    "    score = plda.predict_proba(np.vstack((test_ivector, reference_ivector)))[0, 1]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Audio Files and Extracting MFCCs\n",
    "- *MFCC Extraction*: Converts the raw audio signal into a set of features that capture the spectral characteristics of the voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs_list = []\n",
    "for filename in os.listdir(FOLDER_PATH):\n",
    "   if filename.lower().endswith((\".mp3\",\".mp4\",\".wav\",\".flac\")):\n",
    "        audio_file = os.path.join(FOLDER_PATH, filename)\n",
    "        mfcc_features = extract_mfcc(audio_file)\n",
    "        mfccs_list.append(mfcc_features)\n",
    "\n",
    "mfccs_array = np.vstack(mfccs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing MFCCs\n",
    "- *Standardization*: Ensures that all features are on the same scale, which is important for the performance of the GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "mfccs_array = scaler.fit_transform(mfccs_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the UBM\n",
    "- *UBM*: A GMM that represents the distribution of audio features across all speakers. It is used as a reference model for computing speaker-specific i-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nourg\\Documents\\VS code\\Voice_Biometrics\\.venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:269: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ubm_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubm = GaussianMixture(n_components=NUM_COMPONENTS, covariance_type=COVARIANCE_TYPE, max_iter=100, random_state=42)\n",
    "ubm.fit(mfccs_array)\n",
    "joblib.dump(ubm, 'ubm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Baum-Welch Statistics\n",
    "Computes the Baum-Welch statistics for the MFCC features using the trained UBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, F = compute_baum_welch_statistics(mfccs_array, ubm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the T-Matrix\n",
    "Trains a PCA model to reduce the dimensionality of the Baum-Welch statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t_matrix.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_matrix = PCA(n_components=NUM_IVECTORS)\n",
    "t_matrix.fit(F)\n",
    "joblib.dump(t_matrix, 't_matrix.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting i-Vectors\n",
    "Extracts i-vectors from the Baum-Welch statistics and normalizes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivectors = extract_ivector(F, N, t_matrix)\n",
    "ivectors = np.array([length_normalize(ivector) for ivector in ivectors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving i-Vectors\n",
    "Saves the extracted i-vectors to a file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ivectors.npy', ivectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
